'''Entra√Ænement PPO ULTRA-RAPIDE (30-60 minutes max)
Author: Roberto Lentini (version optimis√©e vitesse)
'''
import pandas as pd
from env import EthereumEnv, CustomAgent
from models import train_agent, test_agent
from tensorflow.keras.optimizers import Adam

if __name__ == "__main__":

    # ========================================
    # ‚ö° CONFIGURATION ULTRA-RAPIDE
    # ========================================
    
    LOOKBACK_WINDOW = 30           # ‚ö° R√©duit de 50 ‚Üí 30 (moins de donn√©es √† traiter)
    TEST_WINDOW = 300              # ‚ö° R√©duit de 500 ‚Üí 300
    
    TRAIN_EPISODES = 300           # ‚ö° DRASTIQUEMENT r√©duit: 2000 ‚Üí 300
    BATCH_SIZE = 128               # ‚ö° R√©duit de 500 ‚Üí 128 (updates plus fr√©quents)
    LEARNING_RATE = 0.0001         # ‚ö° Augment√© pour apprentissage plus rapide
    EPOCHS = 5                     # ‚ö° R√©duit de 15 ‚Üí 5 (suffisant avec bon LR)
    
    # ========================================
    # CHARGEMENT DES DONN√âES
    # ========================================
    
    print("="*60)
    print("‚ö° CONFIGURATION ULTRA-RAPIDE (30-60 min)")
    print("="*60)
    print(f"Episodes: {TRAIN_EPISODES} (au lieu de 2000)")
    print(f"Learning rate: {LEARNING_RATE} (apprentissage rapide)")
    print(f"Epochs per update: {EPOCHS} (efficace)")
    print(f"Batch size: {BATCH_SIZE} (√©quilibr√©)")
    print(f"Lookback: {LOOKBACK_WINDOW} (optimis√©)")
    print("="*60 + "\n")
    
    df = pd.read_csv('cryptoanalysis_data.csv', index_col=False)
    df = df.rename(columns={'price': 'Close', 'date': 'Date'})
    
    # S√©paration Close et Date
    Close = list(df['Close'])
    df = df.drop(['Close'], axis=1)
    Date = df['Date']
    df = df.drop(['Date'], axis=1)
    
    # Normalisation globale
    column_maxes = df.max()
    df_max = column_maxes.max()
    column_mins = df.min()
    df_min = column_mins.min()
    
    normalized_df = (df - df_min) / (df_max - df_min)
    normalized_df['Close'] = Close
    normalized_df['Date'] = Date
    df = normalized_df
    
    # Split train/test
    train_df = df[:-TEST_WINDOW - LOOKBACK_WINDOW]
    test_df = df[-TEST_WINDOW - LOOKBACK_WINDOW:]
    
    print(f"üìä Donn√©es charg√©es:")
    print(f"   Total: {len(df)} points")
    print(f"   Train: {len(train_df)} points")
    print(f"   Test: {len(test_df)} points")
    print(f"   Features: {df.shape[1]}\n")
    
    # ========================================
    # CR√âATION DE L'AGENT OPTIMIS√â VITESSE
    # ========================================
    
    print("ü§ñ Cr√©ation de l'agent PPO rapide...")
    agent = CustomAgent(
        lookback_window_size=LOOKBACK_WINDOW,
        lr=LEARNING_RATE,
        epochs=EPOCHS,
        optimizer=Adam,
        batch_size=64,              # Bon compromis vitesse/stabilit√©
        model="CNN"                 # CNN = rapide et efficace
    )
    
    print("üèãÔ∏è Cr√©ation de l'environnement...")
    train_env = EthereumEnv(
        train_df, 
        lookback_window_size=LOOKBACK_WINDOW
    )
    
    # ========================================
    # ENTRA√éNEMENT RAPIDE
    # ========================================
    
    print("\n" + "="*60)
    print("‚ö° D√âMARRAGE DE L'ENTRA√éNEMENT RAPIDE")
    print("="*60)
    print("‚úÖ Dur√©e estim√©e: 30-60 minutes")
    print("‚úÖ 300 √©pisodes au lieu de 2000")
    print("‚úÖ Lookback r√©duit pour plus de vitesse")
    print("‚úÖ Learning rate augment√© pour convergence rapide")
    print("\nüí° ASTUCE:")
    print("   - Lancez: tensorboard --logdir=logs")
    print("   - Surveillez la courbe de r√©compense")
    print("   - Arr√™tez si r√©compense positive stable")
    print("="*60 + "\n")
    
    train_agent(
        train_env, 
        agent, 
        visualize=False,              # False = beaucoup plus rapide
        train_episodes=TRAIN_EPISODES,
        training_batch_size=BATCH_SIZE
    )
    
    print("\n" + "="*60)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â EN TEMPS RECORD!")
    print("="*60)
    print("üìÅ V√©rifiez le dossier cr√©√©: YYYY_MM_DD_HH_MM_Crypto_trader")
    print("üéØ Cherchez un mod√®le avec r√©compense POSITIVE")
    print("="*60 + "\n")
    
    # ========================================
    # TEST RAPIDE (d√©commenter pour tester)
    # ========================================
    
    # print("üß™ Test rapide du mod√®le...")
    # test_env = EthereumEnv(test_df, lookback_window_size=LOOKBACK_WINDOW)
    # 
    # test_agent(
    #     test_env, 
    #     agent, 
    #     visualize=True, 
    #     test_episodes=5,  # R√©duit pour test rapide
    #     folder="VOTRE_DOSSIER_ICI",
    #     name="VOTRE_MEILLEUR_MODELE",
    #     comment="Test rapide"
    # )